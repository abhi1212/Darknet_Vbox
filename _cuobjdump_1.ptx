






.version 5.0
.target sm_50
.address_size 64



.visible .entry _Z15binarize_kernelPfiS_(
.param .u64 _Z15binarize_kernelPfiS__param_0,
.param .u32 _Z15binarize_kernelPfiS__param_1,
.param .u64 _Z15binarize_kernelPfiS__param_2
)
{
.reg .pred %p<3>;
.reg .f32 %f<3>;
.reg .b32 %r<9>;
.reg .b64 %rd<8>;


ld.param.u64 %rd1, [_Z15binarize_kernelPfiS__param_0];
ld.param.u32 %r2, [_Z15binarize_kernelPfiS__param_1];
ld.param.u64 %rd2, [_Z15binarize_kernelPfiS__param_2];
mov.u32 %r3, %ctaid.x;
mov.u32 %r4, %nctaid.x;
mov.u32 %r5, %ctaid.y;
mad.lo.s32 %r6, %r4, %r5, %r3;
mov.u32 %r7, %ntid.x;
mov.u32 %r8, %tid.x;
mad.lo.s32 %r1, %r6, %r7, %r8;
setp.ge.s32	%p1, %r1, %r2;
@%p1 bra BB0_2;

cvta.to.global.u64 %rd3, %rd2;
cvta.to.global.u64 %rd4, %rd1;
mul.wide.s32 %rd5, %r1, 4;
add.s64 %rd6, %rd4, %rd5;
ld.global.f32 %f1, [%rd6];
setp.ltu.f32	%p2, %f1, 0f00000000;
selp.f32	%f2, 0fBF800000, 0f3F800000, %p2;
add.s64 %rd7, %rd3, %rd5;
st.global.f32 [%rd7], %f2;

BB0_2:
ret;
}


.visible .entry _Z21binarize_input_kernelPfiiS_(
.param .u64 _Z21binarize_input_kernelPfiiS__param_0,
.param .u32 _Z21binarize_input_kernelPfiiS__param_1,
.param .u32 _Z21binarize_input_kernelPfiiS__param_2,
.param .u64 _Z21binarize_input_kernelPfiiS__param_3
)
{
.reg .pred %p<7>;
.reg .f32 %f<16>;
.reg .b32 %r<20>;
.reg .b64 %rd<10>;


ld.param.u64 %rd4, [_Z21binarize_input_kernelPfiiS__param_0];
ld.param.u32 %r6, [_Z21binarize_input_kernelPfiiS__param_1];
ld.param.u32 %r7, [_Z21binarize_input_kernelPfiiS__param_2];
ld.param.u64 %rd3, [_Z21binarize_input_kernelPfiiS__param_3];
cvta.to.global.u64 %rd1, %rd4;
mov.u32 %r8, %nctaid.x;
mov.u32 %r9, %ctaid.y;
mov.u32 %r10, %ctaid.x;
mad.lo.s32 %r11, %r8, %r9, %r10;
mov.u32 %r12, %ntid.x;
mov.u32 %r13, %tid.x;
mad.lo.s32 %r1, %r11, %r12, %r13;
setp.ge.s32	%p1, %r1, %r7;
@%p1 bra BB1_6;

mov.f32 %f14, 0f00000000;
mov.u32 %r18, 0;
mov.f32 %f15, %f14;
setp.lt.s32	%p2, %r6, 1;
@%p2 bra BB1_3;

BB1_2:
mad.lo.s32 %r15, %r18, %r7, %r1;
mul.wide.s32 %rd5, %r15, 4;
add.s64 %rd6, %rd1, %rd5;
ld.global.f32 %f8, [%rd6];
abs.f32 %f9, %f8;
add.f32 %f15, %f15, %f9;
add.s32 %r18, %r18, 1;
setp.lt.s32	%p3, %r18, %r6;
mov.f32 %f14, %f15;
@%p3 bra BB1_2;

BB1_3:
cvt.rn.f32.s32	%f10, %r6;
div.rn.f32 %f4, %f14, %f10;
@%p2 bra BB1_6;

cvta.to.global.u64 %rd2, %rd3;
neg.f32 %f5, %f4;
mov.u32 %r19, 0;

BB1_5:
mad.lo.s32 %r17, %r19, %r7, %r1;
mul.wide.s32 %rd7, %r17, 4;
add.s64 %rd8, %rd1, %rd7;
ld.global.f32 %f11, [%rd8];
setp.gt.f32	%p5, %f11, 0f00000000;
selp.f32	%f12, %f4, %f5, %p5;
add.s64 %rd9, %rd2, %rd7;
st.global.f32 [%rd9], %f12;
add.s32 %r19, %r19, 1;
setp.lt.s32	%p6, %r19, %r6;
@%p6 bra BB1_5;

BB1_6:
ret;
}


.visible .entry _Z23binarize_weights_kernelPfiiS_(
.param .u64 _Z23binarize_weights_kernelPfiiS__param_0,
.param .u32 _Z23binarize_weights_kernelPfiiS__param_1,
.param .u32 _Z23binarize_weights_kernelPfiiS__param_2,
.param .u64 _Z23binarize_weights_kernelPfiiS__param_3
)
{
.reg .pred %p<7>;
.reg .f32 %f<14>;
.reg .b32 %r<24>;
.reg .b64 %rd<19>;


ld.param.u64 %rd12, [_Z23binarize_weights_kernelPfiiS__param_0];
ld.param.u32 %r11, [_Z23binarize_weights_kernelPfiiS__param_1];
ld.param.u32 %r10, [_Z23binarize_weights_kernelPfiiS__param_2];
ld.param.u64 %rd11, [_Z23binarize_weights_kernelPfiiS__param_3];
cvta.to.global.u64 %rd1, %rd12;
mov.u32 %r1, %nctaid.x;
mov.u32 %r2, %ctaid.y;
mov.u32 %r3, %ctaid.x;
mad.lo.s32 %r12, %r1, %r2, %r3;
mov.u32 %r4, %ntid.x;
mov.u32 %r5, %tid.x;
mad.lo.s32 %r13, %r12, %r4, %r5;
setp.ge.s32	%p1, %r13, %r11;
@%p1 bra BB2_7;

mov.f32 %f13, 0f00000000;
setp.lt.s32	%p2, %r10, 1;
@%p2 bra BB2_4;

mad.lo.s32 %r16, %r4, %r12, %r5;
mul.lo.s32 %r17, %r10, %r16;
mul.wide.s32 %rd13, %r17, 4;
add.s64 %rd16, %rd1, %rd13;
mov.u32 %r22, 0;
mov.f32 %f13, 0f00000000;

BB2_3:
ld.global.f32 %f8, [%rd16];
abs.f32 %f9, %f8;
add.f32 %f13, %f13, %f9;
add.s64 %rd16, %rd16, 4;
add.s32 %r22, %r22, 1;
setp.lt.s32	%p3, %r22, %r10;
@%p3 bra BB2_3;

BB2_4:
cvt.rn.f32.s32	%f10, %r10;
div.rn.f32 %f4, %f13, %f10;
@%p2 bra BB2_7;

cvta.to.global.u64 %rd14, %rd11;
neg.f32 %f5, %f4;
mad.lo.s32 %r20, %r4, %r12, %r5;
mul.lo.s32 %r21, %r10, %r20;
mul.wide.s32 %rd15, %r21, 4;
add.s64 %rd18, %rd14, %rd15;
add.s64 %rd17, %rd1, %rd15;
mov.u32 %r23, 0;

BB2_6:
ld.global.f32 %f11, [%rd17];
setp.gt.f32	%p5, %f11, 0f00000000;
selp.f32	%f12, %f4, %f5, %p5;
st.global.f32 [%rd18], %f12;
add.s64 %rd18, %rd18, 4;
add.s64 %rd17, %rd17, 4;
add.s32 %r23, %r23, 1;
setp.lt.s32	%p6, %r23, %r10;
@%p6 bra BB2_6;

BB2_7:
ret;
}


.visible .entry _Z13smooth_kernelPfiiiiifS_(
.param .u64 _Z13smooth_kernelPfiiiiifS__param_0,
.param .u32 _Z13smooth_kernelPfiiiiifS__param_1,
.param .u32 _Z13smooth_kernelPfiiiiifS__param_2,
.param .u32 _Z13smooth_kernelPfiiiiifS__param_3,
.param .u32 _Z13smooth_kernelPfiiiiifS__param_4,
.param .u32 _Z13smooth_kernelPfiiiiifS__param_5,
.param .f32 _Z13smooth_kernelPfiiiiifS__param_6,
.param .u64 _Z13smooth_kernelPfiiiiifS__param_7
)
{
.reg .pred %p<12>;
.reg .f32 %f<13>;
.reg .b32 %r<36>;
.reg .b64 %rd<13>;


ld.param.u64 %rd8, [_Z13smooth_kernelPfiiiiifS__param_0];
ld.param.u32 %r14, [_Z13smooth_kernelPfiiiiifS__param_1];
ld.param.u32 %r11, [_Z13smooth_kernelPfiiiiifS__param_2];
ld.param.u32 %r12, [_Z13smooth_kernelPfiiiiifS__param_3];
ld.param.u32 %r13, [_Z13smooth_kernelPfiiiiifS__param_5];
ld.param.f32 %f3, [_Z13smooth_kernelPfiiiiifS__param_6];
ld.param.u64 %rd7, [_Z13smooth_kernelPfiiiiifS__param_7];
cvta.to.global.u64 %rd1, %rd8;
mov.u32 %r15, %nctaid.x;
mov.u32 %r16, %ctaid.y;
mov.u32 %r17, %ctaid.x;
mad.lo.s32 %r18, %r15, %r16, %r17;
mov.u32 %r19, %ntid.x;
mov.u32 %r20, %tid.x;
mad.lo.s32 %r1, %r18, %r19, %r20;
setp.ge.s32	%p2, %r1, %r14;
@%p2 bra BB3_8;

setp.lt.s32	%p3, %r13, 1;
@%p3 bra BB3_8;

cvta.to.global.u64 %rd9, %rd7;
rem.s32 %r22, %r1, %r11;
div.s32 %r23, %r1, %r11;
rem.s32 %r24, %r23, %r12;
cvt.rn.f32.s32	%f4, %r13;
mul.f32 %f5, %f4, 0fBF000000;
cvt.rzi.s32.f32	%r25, %f5;
mad.lo.s32 %r26, %r23, %r11, %r22;
add.s32 %r2, %r25, %r24;
mul.wide.s32 %rd10, %r26, 4;
add.s64 %rd2, %rd1, %rd10;
add.s64 %rd3, %rd9, %rd10;
add.s32 %r27, %r2, %r23;
sub.s32 %r28, %r27, %r24;
add.s32 %r3, %r25, %r22;
mad.lo.s32 %r4, %r11, %r28, %r3;
mov.u32 %r21, 0;
mov.u32 %r35, %r21;

BB3_3:
mad.lo.s32 %r30, %r11, %r35, %r4;
mul.wide.s32 %rd11, %r30, 4;
add.s64 %rd12, %rd1, %rd11;
add.s32 %r31, %r2, %r35;
setp.gt.s32	%p4, %r31, -1;
setp.lt.s32	%p5, %r31, %r12;
and.pred %p1, %p4, %p5;
mov.u32 %r32, %r3;
mov.u32 %r34, %r21;

BB3_4:
mov.u32 %r7, %r34;
mov.u32 %r6, %r32;
setp.gt.s32	%p6, %r6, -1;
and.pred %p7, %p1, %p6;
setp.lt.s32	%p8, %r6, %r11;
and.pred %p9, %p7, %p8;
mov.f32 %f12, 0f00000000;
@!%p9 bra BB3_6;
bra.uni BB3_5;

BB3_5:
ld.global.f32 %f7, [%rd12];
ld.global.f32 %f8, [%rd2];
sub.f32 %f9, %f7, %f8;
mul.f32 %f12, %f9, %f3;

BB3_6:
ld.global.f32 %f10, [%rd3];
add.f32 %f11, %f12, %f10;
st.global.f32 [%rd3], %f11;
add.s32 %r8, %r6, 1;
add.s64 %rd12, %rd12, 4;
add.s32 %r9, %r7, 1;
setp.lt.s32	%p10, %r9, %r13;
mov.u32 %r32, %r8;
mov.u32 %r34, %r9;
@%p10 bra BB3_4;

add.s32 %r35, %r35, 1;
setp.lt.s32	%p11, %r35, %r13;
@%p11 bra BB3_3;

BB3_8:
ret;
}



